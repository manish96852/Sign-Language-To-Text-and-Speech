# Sign Language to Text & Speech Conversion

## ğŸ“Œ Introduction
This project aims to bridge the communication gap for deaf and mute individuals by converting sign language gestures into text and speech using an AI-powered system.

## ğŸš€ Features
- Real-time sign language detection
- Converts gestures into text and speech
- Uses a CNN-based deep learning model
- Works under different lighting conditions
- User-friendly GUI using Tkinter

## ğŸ“‚ Project Structure
```
â”œâ”€â”€ final_pred.py          # Main script for sign detection
â”œâ”€â”€ requirements.txt       # List of dependencies
â”œâ”€â”€ app.py                 # GUI-based application
â”œâ”€â”€ test.py                # Script for model testing
â”œâ”€â”€ cnn8grps_rad1_model.h5 # Trained CNN model
â”œâ”€â”€ README.md              # Project documentation
â””â”€â”€ Sign_Language_Presentation.pptx  # Project presentation
```

## ğŸ›  Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/your-repo-link.git
   cd sign-language-conversion
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Run the application:
   ```bash
   python app.py
   ```

## ğŸ“Š Model Training
- Dataset: Collected and preprocessed images of hand gestures
- Model: Convolutional Neural Network (CNN)
- Accuracy: 97% (tested in various environments)

## ğŸ” How It Works
1. Webcam captures hand gestures
2. Preprocessing using OpenCV & MediaPipe
3. CNN model predicts the corresponding letter/word
4. Text and speech output is generated

## ğŸ† Future Enhancements
- Support for Indian Sign Language (ISL)
- Mobile app version
- Integration with voice assistants

## ğŸ™Œ Acknowledgments
Thanks to the open-source community and researchers working on sign language recognition.

## ğŸ“© Contact
For any queries or collaborations, reach out at: **your-email@example.com**
